{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_cnn_with_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z65eKBNwlGxY"
      },
      "source": [
        "epoch_size=500\n",
        "batch=16\n",
        "random_seed=1\n",
        "split_ratio=0.3\n",
        "var_name=\"*your_target_y_value_column_name*\"\n",
        "constraint=0 #for remove outlier\n",
        "random_seed=531\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalMaxPooling2D, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, AveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from keras.initializers import glorot_uniform\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import locale\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "\n",
        "inputPath = \"*your_y_value_file*\" \n",
        "\n",
        "#ex) csv file format, column : data_no x1 x2 x3\n",
        "\n",
        "df = pd.read_csv(inputPath, sep=\"\\t\", header=0)\n",
        "for i in df.index:\n",
        "  if df[var_name][i]<constraint:\n",
        "    df.drop([i], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eltzgS-cUX3P"
      },
      "source": [
        "image_path=\"*YOUR IMAGE PATH*\"\n",
        "\n",
        "a=0\n",
        "file_list=os.listdir(image_path)\n",
        "image_data=[]\n",
        "for i in range(len(df['data_no'])):\n",
        "    image_num=df['data_no'][i]\n",
        "    image_name=\"*your_image_name_format_with_data_no*\".format(image_num)\n",
        "    #ex) image_name=\"{}.jpg\",format(image_num)\n",
        "    matching = [s for s in file_list if image_name in s] \n",
        "    if len(matching)!=0:\n",
        "        file_name=matching[0]\n",
        "        base_path=os.path.join(image_path,file_name)\n",
        "        train_array = cv2.imread(base_path, cv2.IMREAD_COLOR)\n",
        "        train_array = cv2.resize(train_array, dsize=(224,224))\n",
        "        image_data.append(train_array)\n",
        "        a=a+1\n",
        "        if a%100 ==0:\n",
        "            print(a)\n",
        "print(a)\n",
        "print(\"complete image load\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WT8F75yUlT_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "max_var=max(df[var_name])\n",
        "y_data=df[var_name]\n",
        "y_data=y_data/max_var\n",
        "\n",
        "split = train_test_split(y_data, image_data, test_size=split_ratio, random_state=random_seed)\n",
        "(y_train,y_valid,image_train,image_valid)=split\n",
        "\n",
        "x_train=np.array(image_train)/255\n",
        "x_valid=np.array(image_valid)/255\n",
        "\n",
        "input_shape = x_train.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl2rm7px9SD9"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP0sTuSv9XKD"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4AYWFgg9cYG"
      },
      "source": [
        "def ResNet50(input_shape=input_shape):\n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1, activation='linear', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "    return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUyLjX9fvNYo"
      },
      "source": [
        "clear_session()\n",
        "model = ResNet50(input_shape)\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
        "history=model.fit(x_train,y_train, epochs=epoch_size, batch_size=batch, shuffle=True, validation_data=(x_valid,y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jqaPDw2BQap"
      },
      "source": [
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_lDE9b77mV"
      },
      "source": [
        "preds = model.predict(x_valid)\n",
        "pred_val=preds.flatten()*max_var\n",
        "testY=np.asarray(y_valid)\n",
        "real_val=testY*max_var\n",
        "print(\"%s\"%(var_name))\n",
        "print(\"real \\t prediction \\t abs_error\")\n",
        "for i in range(len(testY)):\n",
        "  print(\"{:.2f} \\t {:.2f} \\t {:.2f}\".format(real_val[i], pred_val[i],abs(real_val[i]-pred_val[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7J5mO4mCStN"
      },
      "source": [
        "max_v=max(max(real_val),max(pred_val))\n",
        "min_v=min(min(real_val),min(pred_val))\n",
        "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "plt.rcParams['axes.grid'] = True \n",
        "plt.scatter(real_val,pred_val)\n",
        "plt.plot([min_v,max_v],[min_v,max_v],'-k')\n",
        "plt.xlabel(\"real %s\"%(var_name))\n",
        "plt.ylabel(\"prediction %s\"%(var_name))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}